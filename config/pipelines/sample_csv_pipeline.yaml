# Sample pipeline configuration for CSV data processing
name: "csv_data_pipeline"
description: "Process CSV files and load into PostgreSQL"

# Data source configuration
source:
  type: "csv"
  config:
    base_path: "./data/raw"
    encoding: "utf-8"
    delimiter: ","
  
# Source file specification
input:
  file_pattern: "sales_data_*.csv"  # Can use wildcards
  
# Data processing configuration
processing:
  engine: "pandas"  # or "spark"
  operations:
    - type: "clean"
      params:
        operations: 
          - "remove_empty_rows"
          - "trim_strings"
          - "standardize_nulls"
    
    - type: "filter"
      params:
        condition: "revenue > 0 and date >= '2023-01-01'"
    
    - type: "transform"
      params:
        transformations:
          date:
            type: "cast"
            params:
              dtype: "datetime64[ns]"
          
          revenue:
            type: "cast" 
            params:
              dtype: "float64"
          
          customer_name:
            type: "string_operations"
            params:
              operation: "strip"
          
          # Extract date parts
          date:
            type: "extract_date_parts"
            params:
              year: true
              month: true
              day: true
    
    - type: "aggregate"
      params:
        group_by: ["customer_id", "date_year", "date_month"]
        aggregations:
          revenue: ["sum", "mean", "count"]
          quantity: ["sum", "mean"]
    
    - type: "sort"
      params:
        columns: ["date_year", "date_month", "revenue_sum"]
        ascending: [true, true, false]

# Data validation
validation:
  enabled: true
  suite_name: "sales_data_validation"
  auto_generate_expectations: true
  custom_expectations:
    - expectation_type: "expect_column_values_to_be_between"
      kwargs:
        column: "revenue_sum"
        min_value: 0
        max_value: 1000000
    
    - expectation_type: "expect_column_values_to_not_be_null"
      kwargs:
        column: "customer_id"

# Storage configuration  
storage:
  type: "postgresql"
  destination: "sales.monthly_revenue"
  mode: "replace"  # append, replace, or upsert
  
# Data profiling
profiling:
  enabled: true
  generate_report: true
  output_path: "./reports/sales_data_profile.html"

# Monitoring and logging
monitoring:
  track_metrics: true
  alert_on_failure: true
  notification_channels: ["email", "slack"]